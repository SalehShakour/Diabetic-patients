{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## import library"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-05-15T15:05:06.822723800Z",
     "start_time": "2023-05-15T15:05:06.758625100Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mwarnings\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## read main csv file"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv('diabetic_data.csv')\n",
    "df.drop(columns='patient_nbr')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Deal with missing data\n",
    " This is because missing values can affect the accuracy of subsequent preprocessing steps. You can choose to either remove the missing data or fill them in using methods such as mean, median, or mode imputation."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.replace('?', np.nan, inplace=True)\n",
    "df.replace('None', np.nan, inplace=True)\n",
    "df.replace('', np.nan, inplace=True)\n",
    "df.replace(' ', np.nan, inplace=True)\n",
    "\n",
    "# replace missing values in numerical columns with mean\n",
    "numerical_cols = df.select_dtypes(include=['float', 'int']).columns\n",
    "for col in numerical_cols:\n",
    "    mean = df[col].mean()\n",
    "    df[col].fillna(mean, inplace=True)\n",
    "\n",
    "# replace missing values in string columns with mode\n",
    "string_cols = df.select_dtypes(include=['object']).columns\n",
    "for col in string_cols:\n",
    "    mode = df[col].mode()[0]\n",
    "    df[col].fillna(mode, inplace=True)\n",
    "\n",
    "# Check for missing values after imputation\n",
    "missing_values_count = df.isna().sum()\n",
    "print(missing_values_count)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Encode categorical variables\n",
    " If your dataset contains categorical variables, you should encode them as numerical values before performing any further preprocessing. This is because most machine learning algorithms require numerical inputs."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# identify columns with string values\n",
    "str_cols = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "# initialize a LabelEncoder object and a dictionary to store the mappings\n",
    "le = LabelEncoder()\n",
    "mapping_dict = {}\n",
    "\n",
    "# encode each column with string values and store the mappings in the dictionary\n",
    "for col in str_cols:\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    mapping_dict[col] = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "\n",
    "# print the encoded dataframe and the mapping dictionary\n",
    "display(df)\n",
    "print(mapping_dict)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Correlation Coefficient\n",
    " The correlation coefficient measures the strength and direction of the linear relationship between two variables. The code selects important columns by calculating their correlation with the \"readmitted\" column and choosing those with a correlation coefficient greater than a threshold value, which can be used for further analysis or modeling."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# calculate correlation coefficient\n",
    "corr = df.corr()[\"readmitted\"]\n",
    "\n",
    "# plot heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(df.corr(), annot=True, cmap='coolwarm')\n",
    "\n",
    "# select columns with correlation coefficient greater than a threshold\n",
    "threshold = 0.05\n",
    "important_columns = corr[abs(corr) > threshold].index.tolist()\n",
    "\n",
    "# use important columns for further analysis\n",
    "df_important = df[important_columns]\n",
    "df_important_copy =  df_important.copy(deep=True)\n",
    "display(df_important.head())\n",
    "\n",
    "columns = df_important.columns.tolist()\n",
    "print(columns)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Using The Elobw Method"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "wcss_list= []  #Initializing the list for the values of WCSS\n",
    "\n",
    "#Using for loop for iterations from 1 to 10.\n",
    "for i in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=i, init='k-means++', random_state= 42)\n",
    "    kmeans.fit(df_important)\n",
    "    wcss_list.append(kmeans.inertia_)\n",
    "plt.plot(range(1, 11), wcss_list)\n",
    "plt.title('The Elobw Method Graph')\n",
    "plt.xlabel('Number of clusters(k)')\n",
    "plt.ylabel('wcss_list')\n",
    "\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Implement k-means , get silhouette and visualization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "# Apply PCA to reduce the dimensionality of the data\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(df_important)\n",
    "\n",
    "# Apply K-means clustering to the transformed data\n",
    "kmeans = KMeans(n_clusters=3, init='k-means++', random_state= 42)\n",
    "kmeans.fit(df_important)\n",
    "\n",
    "y_pred = kmeans.predict(df_important)\n",
    "silhouette = silhouette_score(df_important, y_pred)\n",
    "\n",
    "print(\"Silhouette:\" , silhouette)\n",
    "# Plot the clustering results in the reduced 2D space\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=kmeans.labels_)\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ______________________________________________________________________"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Implement KNN , get accuracy and visualization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### feature Scaling"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc_X = StandardScaler()\n",
    "X = pd.DataFrame(sc_X.fit_transform(df_important_copy.drop(['readmitted'],axis = 1)),columns=['patient_nbr', 'time_in_hospital', 'num_medications', 'number_outpatient', 'number_emergency', 'number_inpatient', 'number_diagnoses', 'diabetesMed'])\n",
    "y = df_important_copy['readmitted']\n",
    "print(y.shape, X.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test Train Split and Cross Validation methods"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=1/3,random_state=42, stratify=y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "test_scores = []\n",
    "train_scores = []\n",
    "\n",
    "for i in range(1,15):\n",
    "\n",
    "    knn = KNeighborsClassifier(i)\n",
    "    knn.fit(X_train,y_train)\n",
    "\n",
    "    train_scores.append(knn.score(X_train,y_train))\n",
    "    test_scores.append(knn.score(X_test,y_test))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## score that comes from testing on the same datapoints that were used for training\n",
    "max_train_score = max(train_scores)\n",
    "train_scores_ind = [i for i, v in enumerate(train_scores) if v == max_train_score]\n",
    "print('Max train score {} % and k = {}'.format(max_train_score*100,list(map(lambda x: x+1, train_scores_ind))))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## score that comes from testing on the datapoints that were split in the beginning to be used for testing solely\n",
    "max_test_score = max(test_scores)\n",
    "test_scores_ind = [i for i, v in enumerate(test_scores) if v == max_test_score]\n",
    "print('Max test score {} % and k = {}'.format(max_test_score*100,list(map(lambda x: x+1, test_scores_ind))))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Result Visualisation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "p = sns.lineplot(x=range(1,15),y=train_scores,marker='*',label='Train Score')\n",
    "p = sns.lineplot(x=range(1,15),y=test_scores,marker='o',label='Test Score')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
